# ğŸš€ NYC Taxi Big Data Pipeline - Production Deployment

**Projet Big Data - CY Tech 2025**  

JOUDI Haroun, FILALI Amine, OUAD Mouad

---

## ğŸ“Š Vue d'Ensemble du Projet

Ce projet implÃ©mente une pipeline Big Data complÃ¨te de bout en bout pour l'analyse de **36,6 millions** de trajets de taxis NYC en 2023. L'architecture comprend l'ingestion de donnÃ©es avec Spark, un entrepÃ´t de donnÃ©es star schema, un dashboard BI, un service de prÃ©diction ML, et une orchestration automatisÃ©e avec Airflow.

### ğŸ¯ Objectifs Accomplis

- âœ… **Exercise 1:** RÃ©cupÃ©ration automatisÃ©e de 36,6M trajets depuis NYC TLC
- âœ… **Exercise 2:** Validation et ingestion avec Apache Spark (94% taux de rÃ©ussite)
- âœ… **Exercise 3:** EntrepÃ´t de donnÃ©es star schema (5 dimensions + 1 fait)
- âœ… **Exercise 4:** Dashboard Metabase
- âœ… **Exercise 5:** Service ML de prÃ©diction de tarifs (RMSE 6.56 < 10)
- âœ… **Exercise 6:** Orchestration Airflow (pipeline automatisÃ© 5 tÃ¢ches)

---
## ğŸŒ AccÃ¨s aux Services Web

---

| Service | Description | URL | Identifiants |
|---------|-------------|-----|--------------|
| ğŸ”¥ **Spark Master** | Interface de monitoring Spark | [spark-web-ui.haroun-joudi.com](http://spark-web-ui.haroun-joudi.com) | â€” |
| ğŸ“¦ **MinIO Console** | Stockage S3 des donnÃ©es brutes | [minio-console.haroun-joudi.com](https://minio-console.haroun-joudi.com) | minio / minio123 |
| ğŸ“Š **Metabase** | Dashboard d'analyse BI | [metabase.haroun-joudi.com](http://metabase.haroun-joudi.com) | harounjoudi.dev@gmail.com / metabase123 |
| ğŸ¤– **ML Service** | PrÃ©diction tarifaire Streamlit | [ml-service.haroun-joudi.com](https://ml-service.haroun-joudi.com) | â€” |
| ğŸ”„ **Airflow** | Orchestration de pipeline | [airflow.haroun-joudi.com](https://airflow.haroun-joudi.com) | airflow / airflow |
| ğŸ—„ï¸ **PostgreSQL** | Data Warehouse | `bigdata-1:5432` | postgres / postgres |

---

## ğŸ—ï¸ Architecture Technique

### Infrastructure Docker (9 Services)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Docker Network                      â”‚
â”‚           projet_big_data_cytech_25_spark-network   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Spark Clusterâ”‚ Storage Layerâ”‚  Applications Layer   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ spark-master â”‚    MinIO     â”‚      Metabase         â”‚
â”‚ spark-w1     â”‚  PostgreSQL  â”‚    ML Service         â”‚
â”‚ spark-w2     â”‚              â”‚  Airflow (webserver)  â”‚
â”‚              â”‚              â”‚  Airflow (scheduler)  â”‚
â”‚              â”‚              â”‚  Airflow (postgres)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de DonnÃ©es

```mermaid
graph LR
    A[NYC TLC<br/>CloudFront] -->|Ex01: Download| B[MinIO<br/>nyc-raw]
    B -->|Ex02: Spark<br/>Validation| C[MinIO<br/>nyc-validated]
    C -->|Ex02: Spark<br/>Ingestion| D[PostgreSQL<br/>Star Schema]
    D -->|Ex04: Query| E[Metabase<br/>Dashboard]
    C -->|Ex05: Sample<br/>200k| F[ML Training<br/>Random Forest]
    F -->|Ex05: Deploy| G[Streamlit<br/>Interface]
    D -->|Ex06: Airflow<br/>Orchestration| H[End-to-End<br/>Automation]
```

---

## ğŸ“‹ DÃ©ploiement et Gestion

### DÃ©marrage

```bash
# Cloner le projet
git clone <repository>
cd projet_big_data_cytech_25

# Build
docker compose up -d --build

# DÃ©marrer tous les services
docker compose up -d

# VÃ©rifier le statut
docker compose ps
```

---

## ğŸ“Š DÃ©tails des Exercices

### Exercise 1: RÃ©cupÃ©ration de DonnÃ©es

**Objectif:** TÃ©lÃ©charger automatiquement les donnÃ©es NYC 2023

**ImplÃ©mentation:**
- Scala avec MinIO Java SDK
- 12 mois (Janvier-DÃ©cembre 2023)
- Stream direct vers S3

**RÃ©sultats:**
- 38,9M trajets tÃ©lÃ©chargÃ©s
- StockÃ©s dans `s3://nyc-raw/2023/`

**ExÃ©cution:**
```bash
cd ex01_data_retrieval
sbt assembly
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.hadoop:hadoop-aws:3.3.4 \
  target/scala-2.13/ex01-assembly-1.0.jar
```

---

### Exercise 2: Validation et Ingestion Spark

**Objectif:** Valider et charger dans PostgreSQL

**RÃ¨gles de Validation:**
- Distance > 0 et < 500 miles
- Montants >= 0
- Dates valides (2023)
- CoordonnÃ©es GPS NYC

**DÃ©fis RÃ©solus:**

#### 1. OutOfMemoryError
**ProblÃ¨me:** 36,6M lignes causaient crashes mÃ©moire  
**Solution:**
```scala
// Configuration optimisÃ©e
--driver-memory 16g
--executor-memory 12g
.config("spark.sql.autoBroadcastJoinThreshold", "100MB")
```

#### 2. Duplicate Key Errors
**ProblÃ¨me:** Re-exÃ©cution causait violations de contraintes  
**Solution:**
```scala
// Logique idempotente avec upsert
trips.write
  .mode(SaveMode.Append)
  .option("truncate", "false")
  .jdbc(url, "fact_trip", connectionProperties)
```

#### 3. Java 17 Module Access
**ProblÃ¨me:** Erreurs de rÃ©flexion Hadoop  
**Solution:**
```bash
--conf spark.driver.extraJavaOptions="--add-opens=java.base/..."
```

**RÃ©sultats:**
-  36,6M trajets valides (94%)
-  2,3M trajets rejetÃ©s (6%)
-  Temps: ~1 heure
-  Stockage: 11GB PostgreSQL

**ExÃ©cution:**
```bash
cd ex02_data_ingestion
sbt assembly
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --driver-memory 16g \
  --executor-memory 12g \
  --packages org.apache.hadoop:hadoop-aws:3.3.4,org.postgresql:postgresql:42.7.1 \
  target/scala-2.13/ex02-assembly-1.0.jar
```

---

### Exercise 3: SchÃ©ma Star SQL

**Architecture Star Schema:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dim_datetime    â”‚â”€â”€â”
â”‚ (24.3M rows)    â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    dim_zone     â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”‚   fact_trip     â”‚
â”‚   (265 rows)    â”‚  â”‚      â”‚  (36.6M rows)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ dim_payment_typeâ”‚â”€â”€â”¤
â”‚    (7 rows)     â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   dim_vendor    â”‚â”€â”€â”¤
â”‚    (4 rows)     â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  dim_ratecode   â”‚â”€â”€â”˜
â”‚    (7 rows)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tables CrÃ©Ã©es:**

| Table | Type | Lignes | Description |
|-------|------|--------|-------------|
| `dim_datetime` | Dimension | 24,3M | Dates et heures uniques |
| `dim_zone` | Dimension | 265 | Zones taxi NYC |
| `dim_payment_type` | Dimension | 7 | Types de paiement |
| `dim_vendor` | Dimension | 4 | Fournisseurs TLC |
| `dim_ratecode` | Dimension | 7 | Codes tarifaires |
| `fact_trip` | Fait | 36,6M | Transactions de trajets |


---

### Exercise 4: Dashboard Metabase

**Objectif:** Dashboard BI professionnel

**Visualisations:**

![Tableau de Bord d'Analyse NYC Taxi](ex04_dashboard/metabase_graphs.png)

1. **Trajets Quotidiens**
   - Type: Line chart
   - MÃ©trique: COUNT(*) par jour
   - Insight: Tendances temporelles

2. **Distribution GÃ©ographique**
   - Type: Bar chart
   - MÃ©trique: Trajets par borough
   - Insight: Manhattan domine (60%)

3. **Tarif Moyen par Heure**
   - Type: Line chart
   - MÃ©trique: AVG(fare_amount) par heure
   - Insight: Pics aux heures de pointe


4. **Types de Paiement**
   - Type: Pie chart
   - MÃ©trique: Distribution des paiements
   - Insight: Carte bancaire #1 (70%)


**AccÃ¨s:** [metabase.haroun-joudi.com](http://metabase.haroun-joudi.com)

---

### Exercise 5: Service ML de PrÃ©diction

**Objectif:** PrÃ©dire `total_amount` avec RMSE < 10

**Approche:**

#### ModÃ¨le: Random Forest Regressor
```python
RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=10,
    random_state=42
)
```

#### Features Engineered:
- `trip_distance`
- `pickup_hour`, `pickup_day`, `pickup_month`
- `passenger_count`
- One-hot: `PULocationID`, `payment_type`, `RatecodeID`



**RÃ©sultats:**
- RMSE: **6.56** (< 10 target)
- EntraÃ®nement: 10 minutes
- MÃ©moire: <4GB (serveur safe)

**Interface Streamlit:**
- Formulaire de saisie (distance, heure, zone, etc.)
- PrÃ©diction en temps rÃ©el
- Visualisation features importantes

![Tableau de Bord d'Analyse NYC Taxi](ex05_ml_prediction_service/streamlit.png)

---

### Exercise 6: Orchestration Airflow

**Objectif:** Automatiser pipeline end-to-end

**DAG: `nyc_taxi_pipeline`**

```python
# 5 tÃ¢ches en cascade
spark_data_ingestion >> load_data_warehouse >> \
ml_preprocessing >> ml_training >> pipeline_complete
```

**DÃ©tails des TÃ¢ches:**

| # | TÃ¢che | Type | DurÃ©e | Description |
|---|-------|------|-------|-------------|
| 1 | `spark_data_ingestion` | DockerOperator | 30 min | Ingestion Spark complÃ¨te (Ex01-02) |
| 2 | `load_data_warehouse` | BashOperator | 1 min | VÃ©rification PostgreSQL (Ex03) |
| 3 | `ml_preprocessing` | DockerOperator | 5 min | Ã‰chantillonnage donnÃ©es (Ex05) |
| 4 | `ml_training` | DockerOperator | 10 min | EntraÃ®nement modÃ¨le (Ex05) |
| 5 | `pipeline_complete` | BashOperator | Instant | Notification succÃ¨s |

**AccÃ¨s:** [airflow.haroun-joudi.com](http://airflow.haroun-joudi.com)  
**Login:** airflow / airflow

